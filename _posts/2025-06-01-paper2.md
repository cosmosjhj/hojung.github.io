---
layout: post
title: Paper 2
subtitle: 'FreeCG: Free the Design Space of Clebsch-Gordan Transform for Machine Learning Force Fields'
tags: [test]
comments: true
mathjax: true
author: Hojung Jung
---

{: .box-success}
One line summary : This paper enhances DFT calculation by proposing novel architecture with refined loss that considers eigenvalues of the Kohn-Sham equations.

> **TL;DR —** FreeCG turns the traditional “one-CG-per-neighbor” strait-jacket into a **design-free, invariant space**, then layers in three upgrades (Group-CG + Sparse Path, Abstract-Edge Shuffling, Attention Enhancer).  
> The result: **state-of-the-art accuracy *and* 3–4 × speed-ups** on MD17/22, QM9, OC20 **at lower memory**.

---

## 1 Motivation

* **Machine-Learning force fields (MLFFs)** promise **DFT accuracy** while running orders faster, but they must honour *all* molecular symmetries.  
* **Clebsch–Gordan (CG) transforms** are the workhorse for coupling high-order spherical irreps inside equivariant GNNs; unfortunately they must be **applied identically to every neighbour edge** to keep permutation-equivariance. That makes them both *expensive* and *rigid* (no custom per-edge logic).

**FreeCG** asks: *what if we shift CG to a permutation-**invariant** basis first?*

---

## 2 Method

The main method is to design a novel architecture for energy prediction of given molecular system. 


### 2.1 Invariance ⇒ Freedom

> If \(h_i(x)\) are permutation-invariant, **any** function \(g(h_{1}, h_{2}, \dots)\) is also invariant.

Thus, once we build **abstract edges** that are invariant, we may run **any CG transform we like** on them—parameter sharing, neighbour loops, even the number of edges—*without breaking global equivariance*.

### 2.2 Layer schematic (Fig.​1 in the paper)

| Step | What happens | Complexity / effect |
|------|--------------|---------------------|
| **Abstract edges** | ViSNet-style cross-attention compresses all real edges into \(T\) *edge tensors* that are already permutation-invariant. | eliminates per-neighbour CG |
| **Group-CG** | Split \(T\) edges into \(G\) groups; run CG inside each group only → \(O(T^{2}/G)\). | up to 64 × fewer CG paths |
| **Sparse path** | Keep only four \(O(3)\) coupling paths \((l,p)=(1,-1),(2,1)\) (vs. eight in full \(SO(3)\)). | 2–4 × flop cut |
| **Edge shuffling** | Deterministic index shift \(\lfloor 1.5\,T/G \rfloor\) mixes info across groups each layer. | avoids group silos |
| **Attention enhancer** | Dot-product between real edge and all abstract edges, added to cross-attention score. | better long-range coupling |

Mathematically, the **Group-CG** is (simplified):

$$
dE_{i}^{L+1}
=
\sum_{g=1}^{G}
\sum_{l_1,l_2}
\sum_{t_1,t_2 \in U_g}
\mathbf{W}^{l_1,l_2}_{t_1 t_2}\,
\bigl(\mathbf{E}_{i}^{L,l_1}\bigr)_{t_1}
\otimes
\bigl(\hat{\mathbf{E}}_{i}^{L,l_2}\bigr)_{t_2},
\qquad \text{(CG within group)}
$$

where \(U_g\) indexes edges in group \(g\).

### 2.3 Main components of the method

**Abstract Edges**

construct the permutation invariant function with transformer architecture in ViSNet (Wang et al., 2024).

**Group CG transform**

This reduces computational complexity by first split the abstract edges of $E$, $L$, and $EˆL$ into groups, where each index of abstract edge belongs to some group $Ug$.
Then with the group size G (hyper-parameter), 

$$
dE'_{L+1,\ell_{o},p_{o};\,i,t_{o},m_{o}}
= \mathbf{1}\bigl(p_{o}=p_{1}p_{2}\bigr)
\sum_{\ell_{1},\ell_{2}}
\sum_{m_{1},m_{2}}
C^{\ell_{o},\ell_{1},\ell_{2}}_{m_{o}m_{1}m_{2}}
\sum_{t_{1},t_{2}\in U_{g}}
W^{\ell_{o},\ell_{1},\ell_{2}}_{t_{o}t_{1}t_{2}}\,
\bigl[\mathrm{Linear}(E^{L}_{i})\bigr]_{\ell_{1},p_{1},t_{1},m_{1}}
\;\hat{E}^{\,L,\ell_{2},p_{2}}_{i,t_{2},m_{2}}\,.
$$

---

## 3 Experiments

### 3.1 Force-field datasets

| Dataset | Task | Prev. SOTA | **FreeCG** | Δ |
|---------|------|-----------:|-----------:|---:|
| **MD17** (Aspirin) | Force MAE (kcal mol⁻¹ Å⁻¹) | 0.145 (ViSNet) | **0.122** | −15 % |
| **rMD17** (Aspirin) | Force MAE | 0.143 (QuinNet) | **0.121** | −15 % |
| **MD22** (Ac-Ala3-NHMe) | Force MAE | 0.071 (ViSNet-Imp) | **0.053** | −25 % |

### 3.2 Molecular-property regression (QM9)

FreeCG attains **best error on 9 / 12 properties**, beating ViSNet on dipole, polarizability, HOMO, LUMO and gap by 15–20 %.

### 3.3 Catalysis benchmark (OC20 S2EF)

Across in-domain and three out-of-domain splits, FreeCG improves force MAE by 10–13 % versus ViSNet while cutting energy MAE by up to 33 %.

### 3.4 Efficiency

* **Inference speed** on the 166-atom Chignolin mini-protein: fastest among ViSNet, NequIP, Allegro for batch size 32.  
* **Memory:** lowest peak GPU memory among CG-based models.  
* **CG path count:** full CG = 64 paths; Group-CG (\(G = 4\)) + sparse path = **4 paths** (16 × flop drop).

---

## 4 Ablations & extensions

* **Module ablation** (Tab. 7): each component (Group-CG, Shuffling, Sparse path, Attention) yields 3–8 % MAE gain; all together = best.  
* **Shuffle stride:** \(\lfloor 1.5\,T/G \rfloor\) beats 0.5 or 1.0 strides.  
* **Group count** \(G\): more groups → faster inference until memory bandwidth dominates.  
* **Plug-in to QuinNet:** adding FreeCG blocks gives **≈ 2 × faster convergence and lower final MAE** after 1 500 epochs.

---

## 5 Qualitative highlights

* **Mini-protein Chignolin:** FreeCG tracks folded ↔ unfolded energy landscape better than ViSNet and yields lower RMSD during 300 ps MD.  
* **Periodic systems** (water, LiPS): radial-distribution functions reproduced with 50 % lower force MAE than the second-best model.

---

## 6 Strengths & caveats

| Strength | Limitation |
|------------|--------------|
| Breaks the neighbour-wise CG bottleneck, **huge design freedom**. | Still relies on ViSNet backbone; other architectures need adaptation. |
| **\(O(3)\) equivariance** with *fewer* paths than \(SO(3)\). | No explicit treatment of spin–orbit or time-dependent fields. |
| SOTA accuracy **and** faster / leaner than NequIP, Allegro. | Real gains taper when dataset size ≪ neighbour count (small molecules). |
| Plug-and-play: enhances QuinNet with minimal code. | Hyper-params (\(T,G,\text{stride}\)) add tuning surface. |

---

## 7 Take-aways for practitioners

* **Need speed?** Use Group-CG + Sparse path: start with \(T = 12, G = 4\).  
* **Need accuracy?** Keep \(O(3)\) paths but bump abstract-edge count instead of neighbours.  
* **Other GNNs?** Identify any invariant pooling first; drop FreeCG atop.

---

## 8 Conclusion

FreeCG shows that moving the heavy CG transform to **permutation-invariant abstract edges** *completely frees* the design space: you can sparsify, group, shuffle or re-weight paths *at will* while keeping global symmetry.  
The resulting model **matches or beats the best MLFFs on every major benchmark and runs 3–4 × faster**. More importantly, it introduces a *paradigm*—**“invariants first, equivariance later”**—ripe for adoption in robotics, point-cloud vision and beyond.

*Paper:* Shao *et al.* “FreeCG: Free the Design Space of Clebsch–Gordan Transform for Machine-Learning Force Fields”, ICLR 2025.

