---
layout: post
title: Paper 1
subtitle: 'ENHANCING THE SCALABILITY AND APPLICABILITY OF KOHN-SHAM HAMILTONIANS FOR MOLECULAR SYSTEMS'
cover-img: /assets/img/path.jpg
thumbnail-img: /assets/img/thumb.png
share-img: /assets/img/path.jpg
tags: [books, test]
author: Hojung Jung
---

{: .box-success}
**One line summary : This paper enhances DFT calculation by proposing novel architecture with refined loss that considers eigenvalues of the Kohn-Sham equations.**

This is the review of the paper 'ENHANCING THE SCALABILITY AND APPLICABILITY OF KOHN-SHAM HAMILTONIANS FOR MOLECULAR SYSTEMS' published in ICLR 2025. I will summarize backgrounds on DFT, main methods in the paper, main result with addition of my personal thought (discussion). Please feel free to reach me for further discussion and possible idea development.

## 1 Density-Functional Theory (DFT)

In quantum mechanics the properties of a molecule are governed by the
many-electron wave-function, obtained from the time-independent
Schrödinger equation  

$$
\hat H\,\Psi = E\,\Psi.
$$

Finding the ground-state energy by solving this eigen-problem is
computationally prohibitive for large \(N\) (the **many-body** problem).

### 1.0 Why DFT?

**Density-Functional Theory (DFT)** replaces the
\(3N\)-dimensional wave-function \(\Psi(\mathbf r_1,\dots,\mathbf r_N)\)
with the **electron density**

$$
\rho(\mathbf r)=\sum_{i\in\text{occ}} |\psi_i(\mathbf r)|^{2},
$$

which depends on only **three spatial variables**.

* **Hohenberg–Kohn theorems (1964)**  
  guarantee a unique energy functional \(E[\rho]\) and that the exact \(\rho\)
  minimises it.
* **Kohn–Sham equations (1965)** map the interacting system onto an auxiliary
  non-interacting one:

$$
\mathbf H[\rho]\,\mathbf C = \mathbf S\,\mathbf C\,\boldsymbol{\epsilon},
\qquad
\boldsymbol{\epsilon}=\operatorname{diag}(\epsilon_i),
$$

where the KS Hamiltonian  

\[
\mathbf H=\mathbf T+\mathbf V_{\text{ext}}
          +\mathbf V_{\text H}[\rho]+\mathbf V_{\text{xc}}[\rho]
\]

contains **Hartree** (\(\mathbf V_{\text H}\)) and
**exchange–correlation** (\(\mathbf V_{\text{xc}}\)) terms.

---

### 1.1 Kohn–Sham formulation

A molecule \(\mathcal M\) is specified by nuclear charges
\(\{Z_1,\dots,Z_N\}\) and coordinates \(\{\mathbf R_1,\dots,\mathbf R_N\}\):

\[
\mathcal M=\bigl\{Z_{1},\dots,Z_{N},\mathbf R_{1},\dots,\mathbf R_{N}\bigr\}.
\]

DFT solves the **self-consistent** eigen-problem  

\[
\mathbf H\,\mathbf C = \mathbf S\,\mathbf C\,\boldsymbol\epsilon,
\qquad
\rho(\mathbf r)=\sum_{i\in\text{occ}} |\psi_i(\mathbf r)|^{2},
\]

usually by an iterative **self-consistent-field (SCF)** cycle:

\[
\mathbf H^{(k)}\!\bigl(\mathbf C^{(k-1)}\bigr)\,
\mathbf C^{(k)}
      = \mathbf S\,\mathbf C^{(k)}\,\boldsymbol\epsilon^{(k)}.
\]

The SCF loop dominates cost, scaling \(\mathcal O(N^{3\text{–}4})\).

| Symbol | Meaning | Size |
|--------|---------|------|
| \(\mathbf H[\rho]\) | KS Hamiltonian | \(B\times B\) |
| \(\mathbf S\)       | AO overlap     | \(B\times B\) |
| \(\mathbf C\)       | AO → MO coeffs | \(B\times N\) |
| \(\boldsymbol\epsilon\) | diag \((\epsilon_i)\) | \(N\times N\) |

### 1.2 SCF cost is high

There are three steps for traiditional numerical methods for estimating the solutions of SCF method. 

1. **Build** $\mathbf H^{(k)}[\rho^{(k-1)}]$ – $\mathcal O(B^{3})$  
2. **Solve** eigensystem – $\mathcal O(B^{3})$  
3. **Mix** density, test convergence  

Overall complexity: \(\mathcal O(TB^{3})\) with \(B\propto N\).

### 1.3 Directly predicting \(\hat{\mathbf H}\)?

Replacing the SCF cycle with a **neural predictor** for the Hamiltonian
offers a huge speed-up for quantum chemistry workflows.

---

## 2 Method: WALoss + WANet

The author argued that MAE loss between matrix is highly sensitive to perturbations which is prone to error in the perspective of ML. Previous works such as networks such as PhisNet (Unke et al., 2021b) and QHNet (Yu et al., 2023b) optimize loss function built on the MAE loss which leads to instability of the training with the larger size molecules. To prevent this instability they suggest loss based on the eigenvalues which i will explain further in the below.

### 2.1 Element-wise losses break at scale

On **PubChemQH** (40–100 atoms) a \(10^{-2}\) relative MAE in
\(\mathbf H\) produces a  
\(10^{6}\,\text{kcal}\,\text{mol}^{-1}\) energy error.

Perturbation bound  

\[
\bigl|\lambda_i(\hat{\mathbf H},\mathbf S)-\lambda_i(\mathbf H,\mathbf S)\bigr|
\le
\frac{\kappa(\mathbf S)}{\lVert\mathbf S\rVert_2}\,
\lVert\Delta\mathbf H\rVert_{1,1},
\]

shows that ill-conditioned \(\mathbf S\) and large \(B\) amplify entry-wise
errors.

### 2.2 Wave-function Alignment Loss (WALoss)

1. **Simultaneous reduction**  
   find \(\mathbf C^{\star}\) with
   \((\mathbf C^{\star})^{\top}\mathbf S\,\mathbf C^{\star}=\mathbf I\).

2. **Project**  
   \(\tilde{\mathbf H}=(\mathbf C^{\star})^{\top}\hat{\mathbf H}\,\mathbf C^{\star}\).

3. **Align key eigenvalues**

\[
\mathcal L_{\text{WA}}
=\rho\sum_{j\in\text{occ}\cup\{\text{LUMO}\}}
 \bigl|\tilde H_{jj}-\epsilon^{\star}_j\bigr|^{2}
+\xi\sum_{j\notin\text{occ}\cup\{\text{LUMO}\}}
 \bigl|\tilde H_{jj}-\epsilon^{\star}_j\bigr|^{2},
\qquad
\rho\gg\xi.
\]

No back-prop through an eigensolver ⇒ stable.

### 2.3 WANet architecture

| Stage | Core idea | Cost | Role |
|-------|-----------|------|------|
| Node conv.   | eSCN (SO (2))      | \(O(L^{3})\) | Cheap irreps |
| Pair block   | Sparse MoE         | const.       | Off-diagonals |
| Diagonal blk | MACE many-body     | \(O(K\nu)\)  | Correlation   |
| Head         | CG → Hermitian     | —            | \(\hat{\mathbf H}\) |

Entire network is SE(3)-equivariant; head enforces Hermiticity.

---

## 3 Experiments

### 3.1 Datasets

Previous works (QHNet) suggest QH9 dataset which consists of upto 9 heavy atoms while this work provide a new dataset PubChemQH which consists of much larger dataset (40-100 heavy atoms).
Below is the comparison of the QH9 and PubChemQH.

| Set | Size | Atom range | Level |
|-----|------|------------|-------|
| QH9 | 130 k | ≤ 9 heavy | B3LYP/def2-SVP |
| PubChemQH | 50 k | 40–100 | B3LYP/def2-TZV |

### 3.2 Metrics

Experiments are conducted on the different metrics:

Hamiltonian MAE, eigenspectrum MAE, eigen-vector cosine, total-energy MAE, relative SCF steps.

### 3.3 PubChemQH results

The expreimental result on PubChemQH dataset shows the suggested method drastically improves the calculation of DFT. 

| Model | MAE\((E_{\text{tot}})\) | Rel. SCF | MAE\((\mathbf H)\) |
|-------|------------------------:|---------:|-------------------:|
| QHNet            | 6.57 × 10⁴ | 3.7 × | 0.78 |
| QHNet + WA       | 7.56 × 10¹ | 0.9 × | 0.52 |
| **WANet + WA**   | **4.72 × 10¹** | **0.82 ×** | **0.47** |
| Init guess       | 3.74 × 10² | 1.0 × | 0.55 |

Energy error drops **1347 ×**; SCF iterations ↓ 18 %.

The authors also compared the property estimated from the DFT (using predicted Hamiltonian) with the regression models (i.e, property classifiers) and demonstrate it has significant advantage on estimating molecular properties.

---

# 4 Discussion

Here, i will provide my personal discussion points regarding the paper.

**(4-1) Updating Hamiltonian prediction over SCF**

I realized that the main computational bottleneck for WANet does not come form the model inference but from the SCF calculation with the estimated Hamiltonian. This implies one could re-inference Hamiltonian prediction during the SCF calculation. I think we can train the model such that we can obtain more accurate prediction in the later stage of SCF method.


**(4-2) Above traditional SCF**

I think one of the key contribution of this paper is to construct large-scale DFT dataset (PUBChem) which costs running 128 V 100 gpus for one month (which is nearly impossible for most of the labs). Thus, reducing the simulation speed itself (i.e, traditional SCF). Also, SCF method can be far from exact when number of atoms becomes larger. Investigating methods that can even surpass the speed of SCF would be a challenging but important task. One possible direction is to test the model trained on self-generating data (i.e, data constructed from the DFT with the AI-trained models just as in LLMs).

---

## 5 Conclusion

Combining **WALoss** with the **WANet** architecture delivers state-of-the-art accuracy while **cutting SCF cost**,
pushing ML-augmented DFT closer to practical, large-molecule deployment.
